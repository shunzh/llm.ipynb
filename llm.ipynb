{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shunzh/llm.ipynb/blob/main/llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbgcy_Lcnb6K"
      },
      "source": [
        "# Implementing a Decoder-Only Transformer from Scratch\n",
        "\n",
        "We implement a decoder-only Transformer architecture with minimum dependencies. This notebook is organized as follows.\n",
        "\n",
        "- Architecture (with single head self-attention)\n",
        "- Model Training and Greedy Decoding\n",
        "- Other features **(WIP)**\n",
        "  - Sampling algorithms\n",
        "  - KV cache\n",
        "  - Multi-head self-attention\n",
        "  - FlashAttention / memory-efficient attention\n",
        "\n",
        "We first import the necessary libraries and set the random seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XrQMXHWj4nKj"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Set random seed\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ2VP8xCpMYw"
      },
      "source": [
        "## Architecture\n",
        "\n",
        "We first define a model config object with default parameter values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAIQppvnMOeZ"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    # The size of hidden state in transformer, also called d_model\n",
        "    hidden_size: int = 512\n",
        "    # The size of hidden state in MLP in the decoder block\n",
        "    ff_hidden_size: int = 4 * 512\n",
        "    # The number of decoder blocks\n",
        "    num_hidden_layers: int = 2\n",
        "    # Dropout rates for all modules that need dropout\n",
        "    dropout_rate: float = 0.1\n",
        "    vocab_size: int = 10000\n",
        "    max_seq_len: int = 128\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6gyx0Q9Llde"
      },
      "source": [
        "### Decoder Block\n",
        "\n",
        "The decoder block is the core of the transformer. It has four modules inside (where the LayerNorm appears twice):\n",
        "\n",
        "```\n",
        "Input: x (batch_size, seq_len, hidden_size)\n",
        "        │\n",
        "        ▼\n",
        "+-------------------+\n",
        "|   LayerNorm       |\n",
        "+-------------------+\n",
        "        │\n",
        "        ▼\n",
        "+-------------------+\n",
        "|  Self-Attention   |  (single head, with causal mask)\n",
        "+-------------------+\n",
        "        │\n",
        "        ▼\n",
        "+-------------------+\n",
        "|   LayerNorm       |\n",
        "+-------------------+\n",
        "        │\n",
        "        ▼\n",
        "+-------------------+\n",
        "|      MLP          |  (Linear → GELU → Linear)\n",
        "+-------------------+\n",
        "        │\n",
        "        ▼\n",
        "     Output x\n",
        "```\n",
        "\n",
        "Let's define these modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc5qVYV3Nz-I",
        "outputId": "5beee3be-5027-4cf8-97e1-5a0ca79a80ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The size of layer norm output is (batch_size, seq_len, hidden_size): torch.Size([2, 3, 512])\n"
          ]
        }
      ],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-5):\n",
        "        super().__init__()\n",
        "\n",
        "        self.gamma = nn.Parameter(torch.ones(hidden_size)) # (hidden_size,)\n",
        "        self.beta = nn.Parameter(torch.zeros(hidden_size)) # (hidden_size,)\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_len, hidden_size)\n",
        "        mean = x.mean(dim=-1, keepdim=True) # (batch_size, seq_len, 1)\n",
        "        std = x.std(dim=-1, keepdim=True) # (batch_size, seq_len, 1)\n",
        "        return (x - mean) / (std + self.eps) * self.gamma + self.beta # (batch_size, seq_len, hidden_size)\n",
        "\n",
        "\n",
        "# Test layer norm\n",
        "layer_norm = LayerNorm(config.hidden_size)\n",
        "x = torch.randn(2, 3, config.hidden_size)\n",
        "layer_norm_output = layer_norm(x)\n",
        "print(\"The size of layer norm output is (batch_size, seq_len, hidden_size):\", layer_norm_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6LJFxvYtD7R",
        "outputId": "1f0b16a9-dec1-4449-ee0c-8f490b0e30ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The attention matrix is: (Note that due to drop out, the values are scaled to (1 - dropout_rate))\n",
            " tensor([[[1.1111, 0.0000, 0.0000],\n",
            "         [0.4300, 0.6812, 0.0000],\n",
            "         [0.3499, 0.4116, 0.3497]],\n",
            "\n",
            "        [[1.1111, 0.0000, 0.0000],\n",
            "         [0.7287, 0.3824, 0.0000],\n",
            "         [0.3532, 0.2315, 0.5264]]], grad_fn=<MulBackward0>)\n",
            "The shape of output is (batch_size, seq_len, d_head): torch.Size([2, 3, 512])\n"
          ]
        }
      ],
      "source": [
        "class SingleHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Attention: hiddent state to query, key, value\n",
        "        self.c_attn = nn.Linear(hidden_size, 3 * hidden_size)\n",
        "        # Output projection\n",
        "        self.c_proj = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Dropouts\n",
        "        self.attn_dropout = nn.Dropout(dropout_rate)\n",
        "        self.proj_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x, return_attn=False):\n",
        "        # x: (batch_size, seq_len, hidden_size)\n",
        "        batch_size, seq_len, hidden_size_in_data = x.shape\n",
        "        assert self.hidden_size == hidden_size_in_data, f\"Mismatch betwee hidden_size in config {self.hidden_size} and hidden_size in data {hidden_size_in_data}\"\n",
        "\n",
        "        c_attn_output = self.c_attn(x) # (batch_size, seq_len, 3 * hidden_size)\n",
        "\n",
        "        # Split into query, key, and value\n",
        "        q, k, v = c_attn_output.split(self.hidden_size, dim=-1)\n",
        "\n",
        "        # Compute attention scores\n",
        "        # q: (.., seq_len, hidden_size)\n",
        "        # k.transpose(-2, -1): (.., hidden_size, seq_len)\n",
        "        attn = (q @ k.transpose(-2, -1)) / (math.sqrt(self.hidden_size)) # (batch_size, seq_len, seq_len)\n",
        "\n",
        "        # Apply causal mask\n",
        "        mask = torch.tril(torch.ones(1, seq_len, seq_len)).to(attn.device) # (1, seq_len, seq_len)\n",
        "        attn = attn.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        # Softmax\n",
        "        attn = torch.softmax(attn, dim=-1)\n",
        "\n",
        "        # Dropout attention\n",
        "        attn = self.attn_dropout(attn)\n",
        "\n",
        "        # Attention output\n",
        "        # attn: (.., seq_len, seq_len)\n",
        "        # v: (.., seq_len, d_head)\n",
        "        attn_output = attn @ v # (batch_size, seq_len, d_head)\n",
        "\n",
        "        # Final projection\n",
        "        proj_output = self.c_proj(attn_output)\n",
        "        proj_output = self.proj_dropout(proj_output) # (batch_size, seq_len, d_head)\n",
        "\n",
        "        if return_attn:\n",
        "            return proj_output, attn\n",
        "        else:\n",
        "            return proj_output\n",
        "\n",
        "\n",
        "# Test\n",
        "x = torch.randn(2, 3, config.hidden_size)\n",
        "self_attention = SingleHeadSelfAttention(config.hidden_size)\n",
        "output, attn = self_attention(x, return_attn=True)\n",
        "print(\"The attention matrix is: (Note that due to drop out, the values are scaled to (1 - dropout_rate))\\n\", attn)\n",
        "print(\"The shape of output is (batch_size, seq_len, d_head):\", output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psUlysBkKo94",
        "outputId": "fcfc0f84-6efc-4277-eec6-ec891acd961d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output shape: torch.Size([2, 3, 512])\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, hidden_size, ff_hidden_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.ff_hidden_size = ff_hidden_size\n",
        "\n",
        "        self.c_fc = nn.Linear(self.hidden_size, self.ff_hidden_size)\n",
        "        self.act = nn.GELU() # Or other activation functions\n",
        "        self.c_proj = nn.Linear(self.ff_hidden_size, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_len, hidden_size)\n",
        "        x = self.c_fc(x) # (batch_size, seq_len, ff_hidden_size)\n",
        "        x = self.act(x) # (batch_size, seq_len, ff_hidden_size)\n",
        "        x = self.c_proj(x) # (batch_size, seq_len, hidden_size)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Test MLP\n",
        "x = torch.randn(2, 3, config.hidden_size)\n",
        "mlp = MLP(config.hidden_size, config.ff_hidden_size)\n",
        "output = mlp(x)\n",
        "print(\"Output shape:\", output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8yBkjCLNMlj"
      },
      "source": [
        "With all the pieces defined above, we're ready to define the decoder block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tGDbfH6NQID",
        "outputId": "c190baa9-231d-4677-844f-b4540d5a74e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 512])\n"
          ]
        }
      ],
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, hidden_size, ff_hidden_size, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.ln_1 = LayerNorm(hidden_size)\n",
        "        self.attn = SingleHeadSelfAttention(hidden_size, dropout_rate)\n",
        "        self.ln_2 = LayerNorm(hidden_size)\n",
        "        self.mlp = MLP(hidden_size, ff_hidden_size, dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, seq_len, hidden_size)\n",
        "        # Layer norm 1\n",
        "        x = self.ln_1(x)\n",
        "        # Self attention + residual\n",
        "        x = x + self.attn(x)\n",
        "        # Layer norm 2\n",
        "        x = self.ln_2(x)\n",
        "        # MLP + residual\n",
        "        x = x + self.mlp(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# Test Decoder\n",
        "x = torch.randn(2, 3, config.hidden_size)\n",
        "decoder = DecoderBlock(config.hidden_size, config.ff_hidden_size)\n",
        "x = decoder(x)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIT2gSUtf3M_"
      },
      "source": [
        "### The Complete Transformer Model\n",
        "\n",
        "With the Decoder block defined above, we're ready to define the complete Transformer architecture.\n",
        "\n",
        "```\n",
        "Input: input_ids (batch_size, seq_len)\n",
        "        │\n",
        "        ▼\n",
        "+------------------------+\n",
        "|  Token Embedding       |\n",
        "|  Position Embedding    |\n",
        "+------------------------+\n",
        "        │\n",
        "        ▼\n",
        "+------------------------+\n",
        "|   DecoderBlock × N     |  (defined in the previous section)\n",
        "+------------------------+\n",
        "        │\n",
        "        ▼\n",
        "+------------------------+\n",
        "|   Final LayerNorm      |\n",
        "+------------------------+\n",
        "        │\n",
        "        ▼\n",
        "+------------------------+\n",
        "|  Linear (Language Head)|\n",
        "+------------------------+\n",
        "        │\n",
        "        ▼\n",
        "Output: logits (batch_size, seq_len, vocab_size)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHXI6NE32YBv",
        "outputId": "96966009-b190-4061-b32c-2620e9f830b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our Transformer model:\n",
            " Transformer(\n",
            "  (token_embed): Embedding(10000, 512)\n",
            "  (position_embed): Embedding(128, 512)\n",
            "  (embed_dropout): Dropout(p=0.1, inplace=False)\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0-1): 2 x DecoderBlock(\n",
            "      (ln_1): LayerNorm()\n",
            "      (attn): SingleHeadSelfAttention(\n",
            "        (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n",
            "        (c_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (proj_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm()\n",
            "      (mlp): MLP(\n",
            "        (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "        (act): GELU(approximate='none')\n",
            "        (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  (language_head): Linear(in_features=512, out_features=10000, bias=True)\n",
            ")\n",
            "Logits shape: torch.Size([2, 3, 10000])\n"
          ]
        }
      ],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_size,\n",
        "        ff_hidden_size,\n",
        "        vocab_size,\n",
        "        max_seq_len,\n",
        "        num_hidden_layers,\n",
        "        dropout_rate=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.token_embed = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.position_embed = nn.Embedding(max_seq_len, hidden_size)\n",
        "        self.embed_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList([DecoderBlock(hidden_size, ff_hidden_size, dropout_rate) for _ in range(num_hidden_layers)])\n",
        "        # The final layer norm\n",
        "        self.ln_f = nn.LayerNorm(hidden_size)\n",
        "\n",
        "        # The final language head, which maps the last hidden state to logits\n",
        "        self.language_head = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        batch_size, seq_len = input_ids.shape\n",
        "\n",
        "        # Create position ids (0, 1, 2, ..., seq_len-1)\n",
        "        position_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0) # (1, seq_len)\n",
        "\n",
        "        # Embed tokens and positions, apply dropout\n",
        "        x = self.token_embed(input_ids) + self.position_embed(position_ids)\n",
        "        x = self.embed_dropout(x)\n",
        "\n",
        "        # Pass through decoder blocks\n",
        "        for layer in self.hidden_layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # Final layer norm\n",
        "        x = self.ln_f(x)\n",
        "\n",
        "        # Project to vocabulary\n",
        "        logits = self.language_head(x) # (batch_size, seq_len, vocab_size)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "# Test Transformer\n",
        "input_ids = torch.randint(0, config.vocab_size, (2, 3))\n",
        "\n",
        "model = Transformer(\n",
        "    hidden_size=config.hidden_size,\n",
        "    ff_hidden_size=config.ff_hidden_size,\n",
        "    vocab_size=config.vocab_size,\n",
        "    max_seq_len=config.max_seq_len,\n",
        "    num_hidden_layers=config.num_hidden_layers,\n",
        "    dropout_rate=config.dropout_rate,\n",
        ")\n",
        "print(\"Our Transformer model:\\n\", model)\n",
        "\n",
        "logits = model(input_ids)\n",
        "print(\"Logits shape:\", logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM3gL5p6PRfy"
      },
      "source": [
        "## Model Training and Inference\n",
        "\n",
        "Now we are ready to train the Transformer architecture we defined above.\n",
        "\n",
        "Let's first load the training data, tokenize them using the GPT2 tokenizer, and create a dataloader for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfvB3W9lDGJN"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V-LNpgjDBOL"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "# Load tiny_shakespeare dataset\n",
        "dataset = load_dataset(\"karpathy/tiny_shakespeare\", split=\"train\")\n",
        "val_dataset = load_dataset(\"karpathy/tiny_shakespeare\", split=\"validation\")\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Update config\n",
        "config.vocab_size = tokenizer.vocab_size\n",
        "\n",
        "# Tokenize entire corpus\n",
        "def tokenize(example):\n",
        "    return tokenizer(example[\"text\"])\n",
        "\n",
        "tokenized = dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "val_tokenized = val_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])\n",
        "\n",
        "# Flatten input_ids across all examples\n",
        "# (note that tiny_shakespeare only contains one long example)\n",
        "all_tokens = sum(tokenized[\"input_ids\"], [])  # list of ints\n",
        "all_val_tokens = sum(val_tokenized[\"input_ids\"], [])\n",
        "# Use a smaller validation set\n",
        "all_val_tokens = all_val_tokens[:2000]\n",
        "\n",
        "\n",
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, tokens, seq_len):\n",
        "        self.tokens = tokens\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tokens) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.tokens[idx : idx + self.seq_len], dtype=torch.long)\n",
        "        y = torch.tensor(self.tokens[idx + 1 : idx + self.seq_len + 1], dtype=torch.long)\n",
        "        return x, y\n",
        "\n",
        "seq_len = 128\n",
        "dataset = TokenDataset(all_tokens, seq_len)\n",
        "val_dataset = TokenDataset(all_val_tokens, seq_len)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True, pin_memory=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, drop_last=True, pin_memory=True)\n",
        "\n",
        "print(\"Number of batches in training set:\", len(dataloader))\n",
        "print(\"Number of batches in validation set:\", len(val_dataloader))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0U96GZvc3Qx"
      },
      "source": [
        "We're now ready to run the training loop.\n",
        "\n",
        "It will stop when the validation loss keeps going up.\n",
        "You may kill the following cell at any point. The checkpoint with the minimum validation loss will be saved and can be used for inference in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "V8NkQrt5Uzqj",
        "outputId": "c03bf7c3-4c12-4b38-e898-aaa5f46268e6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 0:  45%|████▌     | 8499/18864 [22:25<27:21,  6.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stopping. No improvement in the last 5 steps.\n",
            "\n",
            "Training complete.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "\n",
        "def refresh_plot(train_steps, train_losses, val_steps, val_losses):\n",
        "    clear_output(wait=True)\n",
        "    plt.clf()\n",
        "    plt.plot(train_steps, train_losses, label=\"Train Loss\", marker=\"o\")\n",
        "    plt.plot(val_steps, val_losses, label=\"Val Loss\", marker=\"x\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Training & Validation Loss\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    display(plt.gcf())\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(\n",
        "    model,\n",
        "    dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    epochs,\n",
        "    device=torch.device(\"cpu\"),\n",
        "    log_interval=100,\n",
        "    eval_interval=500,\n",
        "    patience=5,\n",
        "):\n",
        "    model.train()\n",
        "    step = 0\n",
        "    batch_losses = []\n",
        "    train_loss_history = []\n",
        "    val_loss_history = []\n",
        "    train_step_history = []\n",
        "    val_step_history = []\n",
        "\n",
        "    steps_since_best_ckpt = 0\n",
        "    plt.figure(figsize=(8, 5))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for x, y in tqdm(dataloader, desc=f\"Epoch {epoch}\"):\n",
        "            x = x.to(device, non_blocking=True)\n",
        "            y = y.to(device, non_blocking=True)\n",
        "\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses.append(loss.item())\n",
        "            step += 1\n",
        "            refresh = False\n",
        "\n",
        "            if step % log_interval == 0:\n",
        "                avg_loss = sum(batch_losses) / len(batch_losses)\n",
        "                train_loss_history.append(avg_loss)\n",
        "                train_step_history.append(step)\n",
        "                batch_losses = []\n",
        "                refresh = True\n",
        "\n",
        "            if step % eval_interval == 0:\n",
        "                model.eval()\n",
        "                val_loss = 0\n",
        "                count = 0\n",
        "                with torch.no_grad():\n",
        "                    for vx, vy in val_dataloader:\n",
        "                        vx = vx.to(device, non_blocking=True)\n",
        "                        vy = vy.to(device, non_blocking=True)\n",
        "                        logits = model(vx)\n",
        "                        loss = criterion(logits.view(-1, logits.shape[-1]), vy.view(-1))\n",
        "                        val_loss += loss.item()\n",
        "                        count += 1\n",
        "                val_loss /= count\n",
        "\n",
        "                if len(val_loss_history) == 0 or val_loss < min(val_loss_history):\n",
        "                    # This is the best model on validation set so far\n",
        "                    steps_since_best_ckpt = 0\n",
        "\n",
        "                    # Save the model weights\n",
        "                    torch.save(model.state_dict(), \"/content/model.pth\")\n",
        "                else:\n",
        "                    # This is worse than the best model on validation set\n",
        "                    steps_since_best_ckpt += 1\n",
        "\n",
        "                    if steps_since_best_ckpt > patience:\n",
        "                        print(f\"Early stopping. No improvement in the last {patience} steps.\")\n",
        "                        break\n",
        "\n",
        "                val_loss_history.append(val_loss)\n",
        "                val_step_history.append(step)\n",
        "\n",
        "                model.train()\n",
        "                refresh = True\n",
        "\n",
        "            if refresh:\n",
        "                refresh_plot(train_step_history, train_loss_history, val_step_history, val_loss_history)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "# Initialize model\n",
        "model = Transformer(\n",
        "    hidden_size=config.hidden_size,\n",
        "    ff_hidden_size=config.ff_hidden_size,\n",
        "    vocab_size=config.vocab_size,\n",
        "    max_seq_len=config.max_seq_len,\n",
        "    num_hidden_layers=config.num_hidden_layers,\n",
        "    dropout_rate=config.dropout_rate,\n",
        ").to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train(\n",
        "    model,\n",
        "    dataloader,\n",
        "    val_dataloader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    epochs=1,\n",
        "    device=device,\n",
        "    log_interval=100,\n",
        "    eval_interval=500,\n",
        "    patience=5,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdpJYH_TZsdJ"
      },
      "source": [
        "### Greedy Decoding\n",
        "\n",
        "Let's run greedy decoding using the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkk_gYlHfSu5",
        "outputId": "97680c61-ebc9-4e12-d1c9-0fab181966d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "==== Model output ====\n",
            ",\n",
            "And, by the Duke of York,\n",
            "And all the world goes,\n",
            "And, with the rest of York,\n",
            "And, with the Duke of York,\n",
            "And all the rest,\n",
            "And that the king's king,\n",
            "And that the king's king, to the crown,\n",
            "And the king, to the Duke of York,\n",
            "And, by the Duke of York,\n",
            "And made the king's king, and the king's king,\n",
            "And that the king's king,\n",
            "And that the king's king,\n",
            "And that the king was the king's king,\n",
            "And that the king\n"
          ]
        }
      ],
      "source": [
        "def greedy_decode(model, input_ids, max_len, device=torch.device(\"cpu\")):\n",
        "    model.eval()\n",
        "    # input_ids: (batch_size, seq_len)\n",
        "    input_ids = input_ids.to(device)\n",
        "\n",
        "    for _ in range(max_len - input_ids.size(1)):\n",
        "        logits = model(input_ids) # (batch_size, seq_len, vocab_size)\n",
        "        next_token = torch.argmax(logits[:, -1, :], dim=-1, keepdim=True) # (batch_size, 1)\n",
        "        input_ids = torch.cat((input_ids, next_token), dim=-1)\n",
        "\n",
        "    return input_ids\n",
        "\n",
        "\n",
        "#  The training cell above may have been killed. So redefine these variables here.\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "# Initialize model\n",
        "model = Transformer(\n",
        "    hidden_size=config.hidden_size,\n",
        "    ff_hidden_size=config.ff_hidden_size,\n",
        "    vocab_size=config.vocab_size,\n",
        "    max_seq_len=config.max_seq_len,\n",
        "    num_hidden_layers=config.num_hidden_layers,\n",
        "    dropout_rate=config.dropout_rate,\n",
        ").to(device)\n",
        "\n",
        "# Load trained model\n",
        "model.load_state_dict(torch.load(\"/content/model.pth\", map_location=device))\n",
        "\n",
        "# Use an empty prompt\n",
        "input_ids = torch.tensor([[tokenizer.bos_token_id]], dtype=torch.long).to(device)\n",
        "\n",
        "# Run greedy decoding\n",
        "output_ids = greedy_decode(model, input_ids, max_len=128, device=device)\n",
        "generated_text = tokenizer.decode(output_ids[0].tolist(), skip_special_tokens=True)\n",
        "\n",
        "print(\"==== Model output ====\")\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qfjYCMA9cAr"
      },
      "source": [
        "## Other Features\n",
        "\n",
        "TODO Not finished\n",
        "\n",
        "### Multi-Head Self Attention\n",
        "\n",
        "Multi-head is slightly more complicated as we need to divide the `c_attn` output into different heads."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNJYapmO9m3k"
      },
      "outputs": [],
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_heads = num_heads\n",
        "        # Find the embedding size for each head\n",
        "        assert self.hidden_size % self.num_heads == 0\n",
        "        self.d_head = self.hidden_size // self.num_heads\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "        # Attention: hiddent state to query, key, value\n",
        "        self.c_attn = nn.Linear(hidden_size, 3 * hidden_size)\n",
        "        # Output projection\n",
        "        self.c_proj = nn.Linear(hidden_size, hidden_size)\n",
        "\n",
        "        # Dropouts\n",
        "        self.attn_dropout = nn.Dropout(dropout_rate)\n",
        "        self.proj_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Project to QKV and split\n",
        "        qkv = self.c_attn(x)  # (batch_size, seq_len, 3 * hidden_size)\n",
        "        q, k, v = qkv.chunk(3, dim=-1)\n",
        "\n",
        "        # Reshape and transpose for multi-head attention\n",
        "        q = q.view(batch_size, seq_len, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        k = k.view(batch_size, seq_len, self.num_heads, self.d_head).transpose(1, 2)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.d_head).transpose(1, 2)\n",
        "\n",
        "        # Attention scores\n",
        "        attn_scores = (q @ k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
        "\n",
        "        # Causal mask\n",
        "        mask = torch.tril(torch.ones(seq_len, seq_len, device=x.device)).unsqueeze(0).unsqueeze(0)\n",
        "        attn_scores = attn_scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        # Softmax and dropout\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.attn_dropout(attn_weights)\n",
        "\n",
        "        # Weighted sum of values\n",
        "        attn_output = attn_weights @ v  # (batch_size, num_heads, seq_len, d_head)\n",
        "\n",
        "        # Concatenate heads\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)\n",
        "\n",
        "        # Final projection + dropout\n",
        "        out = self.c_proj(attn_output)\n",
        "        out = self.proj_dropout(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYzZBlnbyntI"
      },
      "source": [
        "## Other Useful Resources\n",
        "\n",
        "- We use [Hugging Face's implementation of GPT2](https://github.com/huggingface/transformers/blob/main/src/transformers/models/gpt2/modeling_gpt2.py) as a reference.\n",
        "- [The Illustrated GPT-2](https://jalammar.github.io/illustrated-gpt2/): A blog on illustrating GPT2.\n",
        "- [llm.c](https://github.com/karpathy/llm.c): Implementation of LLM from scratch in C.\n",
        "- Original paper:\n",
        "    - Vaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}